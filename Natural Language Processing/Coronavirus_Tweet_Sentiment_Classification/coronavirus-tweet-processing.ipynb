{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Natural Language Processing Project: Coronavirus Tweets"},{"metadata":{},"cell_type":"markdown","source":"Coded by Luna McBride, following ideas in the Kaggle NLP course"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport spacy # NLP\nfrom sklearn.svm import LinearSVC\nimport re # regular expressions\nimport html # HTML content, like &amp;\nfrom spacy.lang.en.stop_words import STOP_WORDS # stopwords\nfrom sklearn.model_selection import train_test_split # training and testing a model\nfrom spacy.util import minibatch # batches for training\nimport random # randomizing for training\n\nnlp = spacy.load('en_core_web_lg') #Load spacy, up here so I do not have to load it constantly\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":340,"outputs":[{"output_type":"stream","text":"/kaggle/input/covid-19-nlp-text-classification/Corona_NLP_test.csv\n/kaggle/input/covid-19-nlp-text-classification/Corona_NLP_train.csv\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Read in the data files"},{"metadata":{},"cell_type":"markdown","source":"Note: just read_csv(\"file\") causes error here. Source for fix: https://stackoverflow.com/questions/18171739/unicodedecodeerror-when-reading-csv-file-in-pandas-with-python"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"../input/covid-19-nlp-text-classification/Corona_NLP_train.csv\", encoding = \"ISO-8859-1\") #Load the training set\ntrain.head() #Take a peek at the training set","execution_count":341,"outputs":[{"output_type":"execute_result","execution_count":341,"data":{"text/plain":"   UserName  ScreenName   Location     TweetAt  \\\n0      3799       48751     London  16-03-2020   \n1      3800       48752         UK  16-03-2020   \n2      3801       48753  Vagabonds  16-03-2020   \n3      3802       48754        NaN  16-03-2020   \n4      3803       48755        NaN  16-03-2020   \n\n                                       OriginalTweet           Sentiment  \n0  @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...             Neutral  \n1  advice Talk to your neighbours family to excha...            Positive  \n2  Coronavirus Australia: Woolworths to give elde...            Positive  \n3  My food stock is not the only one which is emp...            Positive  \n4  Me, ready to go at supermarket during the #COV...  Extremely Negative  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>UserName</th>\n      <th>ScreenName</th>\n      <th>Location</th>\n      <th>TweetAt</th>\n      <th>OriginalTweet</th>\n      <th>Sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3799</td>\n      <td>48751</td>\n      <td>London</td>\n      <td>16-03-2020</td>\n      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n      <td>Neutral</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3800</td>\n      <td>48752</td>\n      <td>UK</td>\n      <td>16-03-2020</td>\n      <td>advice Talk to your neighbours family to excha...</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3801</td>\n      <td>48753</td>\n      <td>Vagabonds</td>\n      <td>16-03-2020</td>\n      <td>Coronavirus Australia: Woolworths to give elde...</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3802</td>\n      <td>48754</td>\n      <td>NaN</td>\n      <td>16-03-2020</td>\n      <td>My food stock is not the only one which is emp...</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3803</td>\n      <td>48755</td>\n      <td>NaN</td>\n      <td>16-03-2020</td>\n      <td>Me, ready to go at supermarket during the #COV...</td>\n      <td>Extremely Negative</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv(\"../input/covid-19-nlp-text-classification/Corona_NLP_test.csv\", encoding = \"ISO-8859-1\") #Load the testing set\ntest.head() #Take a peek at the testing set","execution_count":342,"outputs":[{"output_type":"execute_result","execution_count":342,"data":{"text/plain":"   UserName  ScreenName             Location     TweetAt  \\\n0         1       44953                  NYC  02-03-2020   \n1         2       44954          Seattle, WA  02-03-2020   \n2         3       44955                  NaN  02-03-2020   \n3         4       44956          Chicagoland  02-03-2020   \n4         5       44957  Melbourne, Victoria  03-03-2020   \n\n                                       OriginalTweet           Sentiment  \n0  TRENDING: New Yorkers encounter empty supermar...  Extremely Negative  \n1  When I couldn't find hand sanitizer at Fred Me...            Positive  \n2  Find out how you can protect yourself and love...  Extremely Positive  \n3  #Panic buying hits #NewYork City as anxious sh...            Negative  \n4  #toiletpaper #dunnypaper #coronavirus #coronav...             Neutral  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>UserName</th>\n      <th>ScreenName</th>\n      <th>Location</th>\n      <th>TweetAt</th>\n      <th>OriginalTweet</th>\n      <th>Sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>44953</td>\n      <td>NYC</td>\n      <td>02-03-2020</td>\n      <td>TRENDING: New Yorkers encounter empty supermar...</td>\n      <td>Extremely Negative</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>44954</td>\n      <td>Seattle, WA</td>\n      <td>02-03-2020</td>\n      <td>When I couldn't find hand sanitizer at Fred Me...</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>44955</td>\n      <td>NaN</td>\n      <td>02-03-2020</td>\n      <td>Find out how you can protect yourself and love...</td>\n      <td>Extremely Positive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>44956</td>\n      <td>Chicagoland</td>\n      <td>02-03-2020</td>\n      <td>#Panic buying hits #NewYork City as anxious sh...</td>\n      <td>Negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>44957</td>\n      <td>Melbourne, Victoria</td>\n      <td>03-03-2020</td>\n      <td>#toiletpaper #dunnypaper #coronavirus #coronav...</td>\n      <td>Neutral</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"---"},{"metadata":{},"cell_type":"markdown","source":"# Check for Nulls"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check for nulls in all columns in Train\nprint(\"Train CSV: \\n\")\nprint(train[\"UserName\"].isnull().any())\nprint(train[\"ScreenName\"].isnull().any())\nprint(train[\"Location\"].isnull().any())\nprint(train[\"TweetAt\"].isnull().any())\nprint(train[\"OriginalTweet\"].isnull().any())\nprint(train[\"Sentiment\"].isnull().any())\n    \n#Location has a null\ntrain[\"Location\"] = train[\"Location\"].fillna(\"Unknown\") #Fill the null values with \"Unknown\"\nprint(\"Location: \", train[\"Location\"].isnull().any(), \"\\n\") #Print the now fixed location to make sure it is truly fixed\n\n# Check for nulls in all columns in Test\nprint(\"Test CSV: \\n\")\nprint(test[\"UserName\"].isnull().any())\nprint(test[\"ScreenName\"].isnull().any())\nprint(test[\"Location\"].isnull().any())\nprint(test[\"TweetAt\"].isnull().any())\nprint(test[\"OriginalTweet\"].isnull().any())\nprint(test[\"Sentiment\"].isnull().any())\n\n#Location has a null\ntest[\"Location\"] = test[\"Location\"].fillna(\"Unknown\") #Fill the null values with \"Unknown\"\nprint(\"Location: \", test[\"Location\"].isnull().any(), \"\\n\") #Print the now fixed location to make sure it is truly fixed","execution_count":343,"outputs":[{"output_type":"stream","text":"Train CSV: \n\nFalse\nFalse\nTrue\nFalse\nFalse\nFalse\nLocation:  False \n\nTest CSV: \n\nFalse\nFalse\nTrue\nFalse\nFalse\nFalse\nLocation:  False \n\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"All nulls removed"},{"metadata":{},"cell_type":"markdown","source":"---"},{"metadata":{},"cell_type":"markdown","source":"# Check OriginalTweet for empty strings"},{"metadata":{"trusted":true},"cell_type":"code","source":"empty = train[\"OriginalTweet\"].apply(lambda x: print(\"One\") if not x else x) #Prints \"One\" if there are any empty strings\nempty2 = test[\"OriginalTweet\"].apply(lambda x: print(\"One\") if not x else x) #Prints \"One\" if there are any empty strings","execution_count":344,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"No print statements. No empty strings here."},{"metadata":{},"cell_type":"markdown","source":"---"},{"metadata":{},"cell_type":"markdown","source":"# Tweet Processing"},{"metadata":{},"cell_type":"markdown","source":"Sources for Tweet Processing: https://towardsdatascience.com/basic-tweet-preprocessing-in-python-efd8360d529e , https://medium.com/analytics-vidhya/working-with-twitter-data-b0aa5419532 , https://www.analyticsvidhya.com/blog/2019/08/how-to-remove-stopwords-text-normalization-nltk-spacy-gensim-python/ ,  https://stackoverflow.com/questions/2087370/decode-html-entities-in-python-string , plus some general regex searches."},{"metadata":{"trusted":true},"cell_type":"code","source":"punctuations = \"\"\"!()-![]{};:+'\"\\,<>./?@#$%^&*_~Â\"\"\" #List of punctuations to remove, including a weird A that will not process out any other way\n\n#CleanTweets: parces the tweets and removes punctuation, stop words, digits, and links.\n#Input: the list of tweets that need parsing\n#Output: the parsed tweets\ndef cleanTweets(tweetParse):\n    for i in range(0,len(tweetParse)):\n        tweet = tweetParse[i] #Putting the tweet into a variable so that it is not calling tweetParse[i] over and over\n        tweet = html.unescape(tweet) #Removes leftover HTML elements, such as &amp;\n        tweet = re.sub(r\"@\\w+\", ' ', tweet) #Completely removes @'s, as other peoples' usernames mean nothing\n        tweet = re.sub(r'https\\S+', ' ', tweet) #Removes links, as links provide no data in tweet analysis in themselves\n        tweet = re.sub(r\"\\d+\\S+\", ' ', tweet) #Removes numbers, as well as cases like the \"th\" in \"14th\"\n        tweet = ''.join([punc for punc in tweet if not punc in punctuations]) #Removes the punctuation defined above\n        tweet = tweet.lower() #Turning the tweets lowercase real quick for later use\n    \n        tweetWord = tweet.split() #Splits the tweet into individual words\n        tweetParse[i] = ''.join([word + \" \" for word in tweetWord if nlp.vocab[word].is_stop == False]) #Checks if the words are stop words\n        \n    return tweetParse #Returns the parsed tweets\n\n#Jeez, this whole NLP project (plus the kaggle course) has thrown a lot of use of making a list via _ for _ if _\n\ntrainCopy = train[\"OriginalTweet\"].copy() #Copies the train tweets, using a copy to ensure I do not screw it up\ntestCopy = test[\"OriginalTweet\"].copy() #Copies the test tweets, using a copy to ensure I do not screw it up\n\ntrainTweets = cleanTweets(trainCopy) #Calls the cleanTweets method to clean the train tweets\ntestTweets = cleanTweets(testCopy) #Calls the cleanTweets method to clean the test tweets\n\ntrain[\"CleanTweet\"] = trainTweets #Puts the clean train tweets into a new column\ntest[\"CleanTweet\"] = testTweets #Puts the clean test tweets into a new column\ntrain.head() #Take a peek at the new addition to the data","execution_count":345,"outputs":[{"output_type":"execute_result","execution_count":345,"data":{"text/plain":"   UserName  ScreenName   Location     TweetAt  \\\n0      3799       48751     London  16-03-2020   \n1      3800       48752         UK  16-03-2020   \n2      3801       48753  Vagabonds  16-03-2020   \n3      3802       48754    Unknown  16-03-2020   \n4      3803       48755    Unknown  16-03-2020   \n\n                                       OriginalTweet           Sentiment  \\\n0  @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...             Neutral   \n1  advice Talk to your neighbours family to excha...            Positive   \n2  Coronavirus Australia: Woolworths to give elde...            Positive   \n3  My food stock is not the only one which is emp...            Positive   \n4  Me, ready to go at supermarket during the #COV...  Extremely Negative   \n\n                                          CleanTweet  \n0                                                     \n1  advice talk neighbours family exchange phone n...  \n2  coronavirus australia woolworths elderly disab...  \n3  food stock dont panic food need stay calm stay...  \n4  ready supermarket covid outbreak im paranoid f...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>UserName</th>\n      <th>ScreenName</th>\n      <th>Location</th>\n      <th>TweetAt</th>\n      <th>OriginalTweet</th>\n      <th>Sentiment</th>\n      <th>CleanTweet</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3799</td>\n      <td>48751</td>\n      <td>London</td>\n      <td>16-03-2020</td>\n      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n      <td>Neutral</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3800</td>\n      <td>48752</td>\n      <td>UK</td>\n      <td>16-03-2020</td>\n      <td>advice Talk to your neighbours family to excha...</td>\n      <td>Positive</td>\n      <td>advice talk neighbours family exchange phone n...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3801</td>\n      <td>48753</td>\n      <td>Vagabonds</td>\n      <td>16-03-2020</td>\n      <td>Coronavirus Australia: Woolworths to give elde...</td>\n      <td>Positive</td>\n      <td>coronavirus australia woolworths elderly disab...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3802</td>\n      <td>48754</td>\n      <td>Unknown</td>\n      <td>16-03-2020</td>\n      <td>My food stock is not the only one which is emp...</td>\n      <td>Positive</td>\n      <td>food stock dont panic food need stay calm stay...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3803</td>\n      <td>48755</td>\n      <td>Unknown</td>\n      <td>16-03-2020</td>\n      <td>Me, ready to go at supermarket during the #COV...</td>\n      <td>Extremely Negative</td>\n      <td>ready supermarket covid outbreak im paranoid f...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"***Important note***: there are various rows that become blank strings after processing. After a bit of exploration, these blank strings have different sentiments (ie. the train set's 186 and 13777, which are neutral and negative respectively). Below is the list of the indecies of empty strings after preprocessing. These will be removed further below. It is important to note this, as empty tweets give no information and could skew the model with different sentiments."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(trainTweets.loc[trainTweets == \"\"], \"\\n \\n\") #Print the row numbers with empty clean train tweets\nprint(testTweets.loc[testTweets == \"\"]) #Print the row number with empty clean test tweets","execution_count":346,"outputs":[{"output_type":"stream","text":"0        \n16       \n186      \n583      \n2190     \n5214     \n5946     \n8841     \n12410    \n13777    \n13843    \n14840    \n16920    \n16924    \n18437    \n22994    \n27932    \n28549    \n28604    \n28987    \n29888    \n30345    \n30473    \n31116    \n31293    \n31440    \n31627    \n31657    \n32455    \n35563    \n35565    \n35601    \n36781    \n37646    \n40893    \nName: OriginalTweet, dtype: object \n \n\n3066    \n3195    \nName: OriginalTweet, dtype: object\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#RemoveBlanks: removes tweets that became blank after processing\n#Input: the dataframe to look at\n#Output: none\ndef removeBlanks(df):\n    df[\"CleanTweet\"] = df[\"CleanTweet\"].apply(lambda x: np.nan if not x else x) #Changes blank strings to nan\n    df.dropna(subset = [\"CleanTweet\"], inplace = True) #Drops the rows newly assigned to nan\n    df.reset_index(drop=True, inplace=True) #Reset indecies so we can still loop through without error\n\nremoveBlanks(train) #Removes the blanks from the train set\nremoveBlanks(test) #Removes the blanks from the test set\ntrain.head() #Opens up the train to take a peek, as the first one was blank in the training set","execution_count":347,"outputs":[{"output_type":"execute_result","execution_count":347,"data":{"text/plain":"   UserName  ScreenName                   Location     TweetAt  \\\n0      3800       48752                         UK  16-03-2020   \n1      3801       48753                  Vagabonds  16-03-2020   \n2      3802       48754                    Unknown  16-03-2020   \n3      3803       48755                    Unknown  16-03-2020   \n4      3804       48756  ÃT: 36.319708,-82.363649  16-03-2020   \n\n                                       OriginalTweet           Sentiment  \\\n0  advice Talk to your neighbours family to excha...            Positive   \n1  Coronavirus Australia: Woolworths to give elde...            Positive   \n2  My food stock is not the only one which is emp...            Positive   \n3  Me, ready to go at supermarket during the #COV...  Extremely Negative   \n4  As news of the regionÂs first confirmed COVID...            Positive   \n\n                                          CleanTweet  \n0  advice talk neighbours family exchange phone n...  \n1  coronavirus australia woolworths elderly disab...  \n2  food stock dont panic food need stay calm stay...  \n3  ready supermarket covid outbreak im paranoid f...  \n4  news regions confirmed covid case came sulliv...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>UserName</th>\n      <th>ScreenName</th>\n      <th>Location</th>\n      <th>TweetAt</th>\n      <th>OriginalTweet</th>\n      <th>Sentiment</th>\n      <th>CleanTweet</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3800</td>\n      <td>48752</td>\n      <td>UK</td>\n      <td>16-03-2020</td>\n      <td>advice Talk to your neighbours family to excha...</td>\n      <td>Positive</td>\n      <td>advice talk neighbours family exchange phone n...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3801</td>\n      <td>48753</td>\n      <td>Vagabonds</td>\n      <td>16-03-2020</td>\n      <td>Coronavirus Australia: Woolworths to give elde...</td>\n      <td>Positive</td>\n      <td>coronavirus australia woolworths elderly disab...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3802</td>\n      <td>48754</td>\n      <td>Unknown</td>\n      <td>16-03-2020</td>\n      <td>My food stock is not the only one which is emp...</td>\n      <td>Positive</td>\n      <td>food stock dont panic food need stay calm stay...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3803</td>\n      <td>48755</td>\n      <td>Unknown</td>\n      <td>16-03-2020</td>\n      <td>Me, ready to go at supermarket during the #COV...</td>\n      <td>Extremely Negative</td>\n      <td>ready supermarket covid outbreak im paranoid f...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3804</td>\n      <td>48756</td>\n      <td>ÃT: 36.319708,-82.363649</td>\n      <td>16-03-2020</td>\n      <td>As news of the regionÂs first confirmed COVID...</td>\n      <td>Positive</td>\n      <td>news regions confirmed covid case came sulliv...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"And to check if that caught everything"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train[\"CleanTweet\"].loc[train[\"CleanTweet\"] == \"\"], \"\\n \\n\") #Print the row number that still has empty clean train tweets\nprint(test[\"CleanTweet\"].loc[test[\"CleanTweet\"] == \"\"]) #Print the row number that still has empty clean test tweets","execution_count":348,"outputs":[{"output_type":"stream","text":"Series([], Name: CleanTweet, dtype: object) \n \n\nSeries([], Name: CleanTweet, dtype: object)\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"---"},{"metadata":{},"cell_type":"markdown","source":"# Adding Numeric Sentiments and Remove Extremes"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Sentiments: A function to turn the word sentiments into numerical values for the Train set, 0, 1, 2, 0 being negative, 2 being positive.\n# This function also makes incorrect values in labels -1, as nothing else is -1\ndef sentiments(x):\n    if x == \"Negative\":\n        return 0\n    if x == \"Neutral\":\n        return 1\n    return 2\n\ndef removeExtremes(x):\n    if x == \"Extremely Negative\":\n        return \"Negative\"\n    if x == \"Extremely Positive\":\n        return \"Positive\"\n    return x\n\n#Extremes were causing problems in the model, as it is hard to exemplify extreme to a computer\n#These change the extremes to just their counterparts so it is not a necessary hurdle\ntrain[\"Sentiment\"] = train[\"Sentiment\"].apply(removeExtremes)\ntest[\"Sentiment\"] = test[\"Sentiment\"].apply(removeExtremes)\n\ntrain[\"NumSentiment\"] = train[\"Sentiment\"].apply(sentiments) #Add a row into train for numerical sentiment\ntest[\"NumSentiment\"] = test[\"Sentiment\"].apply(sentiments) #Add a row into test for numerical sentiment\ntest.head() #Display the test and see if it has numerical sentiment","execution_count":349,"outputs":[{"output_type":"execute_result","execution_count":349,"data":{"text/plain":"   UserName  ScreenName             Location     TweetAt  \\\n0         1       44953                  NYC  02-03-2020   \n1         2       44954          Seattle, WA  02-03-2020   \n2         3       44955              Unknown  02-03-2020   \n3         4       44956          Chicagoland  02-03-2020   \n4         5       44957  Melbourne, Victoria  03-03-2020   \n\n                                       OriginalTweet Sentiment  \\\n0  TRENDING: New Yorkers encounter empty supermar...  Negative   \n1  When I couldn't find hand sanitizer at Fred Me...  Positive   \n2  Find out how you can protect yourself and love...  Positive   \n3  #Panic buying hits #NewYork City as anxious sh...  Negative   \n4  #toiletpaper #dunnypaper #coronavirus #coronav...   Neutral   \n\n                                          CleanTweet  NumSentiment  \n0  trending new yorkers encounter supermarket she...             0  \n1  couldnt find hand sanitizer fred meyer turned ...             2  \n2               find protect loved ones coronavirus              2  \n3  panic buying hits newyork city anxious shopper...             0  \n4  toiletpaper dunnypaper coronavirus coronavirus...             1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>UserName</th>\n      <th>ScreenName</th>\n      <th>Location</th>\n      <th>TweetAt</th>\n      <th>OriginalTweet</th>\n      <th>Sentiment</th>\n      <th>CleanTweet</th>\n      <th>NumSentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>44953</td>\n      <td>NYC</td>\n      <td>02-03-2020</td>\n      <td>TRENDING: New Yorkers encounter empty supermar...</td>\n      <td>Negative</td>\n      <td>trending new yorkers encounter supermarket she...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>44954</td>\n      <td>Seattle, WA</td>\n      <td>02-03-2020</td>\n      <td>When I couldn't find hand sanitizer at Fred Me...</td>\n      <td>Positive</td>\n      <td>couldnt find hand sanitizer fred meyer turned ...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>44955</td>\n      <td>Unknown</td>\n      <td>02-03-2020</td>\n      <td>Find out how you can protect yourself and love...</td>\n      <td>Positive</td>\n      <td>find protect loved ones coronavirus</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>44956</td>\n      <td>Chicagoland</td>\n      <td>02-03-2020</td>\n      <td>#Panic buying hits #NewYork City as anxious sh...</td>\n      <td>Negative</td>\n      <td>panic buying hits newyork city anxious shopper...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>44957</td>\n      <td>Melbourne, Victoria</td>\n      <td>03-03-2020</td>\n      <td>#toiletpaper #dunnypaper #coronavirus #coronav...</td>\n      <td>Neutral</td>\n      <td>toiletpaper dunnypaper coronavirus coronavirus...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"---"},{"metadata":{},"cell_type":"markdown","source":"# Begin the pipeline"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Pipe for processing, copied from the kaggle course\ntextcat = nlp.create_pipe(\n              \"textcat\",\n              config={\n                \"exclusive_classes\": True,\n                \"architecture\": \"bow\"})\ntry:\n    nlp.add_pipe(textcat) #Add the pipe\n    print(\"Pipeline loaded\") #Print for if the pipeline is loaded\nexcept:\n    nlp.remove_pipe(\"textcat\") #delete the pipe to reload\n    nlp.add_pipe(textcat) #Add the pipe\n    print(\"Pipeline now loaded\") #Print for if the pipeline is loaded\n\n#Adding labels for the tweets\ntextcat.add_label(\"Negative\")\ntextcat.add_label(\"Neutral\")\ntextcat.add_label(\"Positive\")","execution_count":350,"outputs":[{"output_type":"stream","text":"Pipeline loaded\n","name":"stdout"},{"output_type":"execute_result","execution_count":350,"data":{"text/plain":"1"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"---"},{"metadata":{},"cell_type":"markdown","source":"# Training via the training set"},{"metadata":{},"cell_type":"markdown","source":"Based on the code from the kaggle course Text Classification"},{"metadata":{"trusted":true},"cell_type":"code","source":"#TrainData: a function to train the model to the train data. Modeled after the one in the kaggle class\n#Input: the model, the training data, and an optimizer\n#Output: losses\ndef trainData(model, data, optimize):\n    losses = {} #A set for the losses data\n    random.seed() #Randomizing the seed of shuffling data\n    random.shuffle(data) #Shuffles the data\n    \n    batches = minibatch(data, size=10) #Creates batches of texts\n    \n    #For each batch of texts\n    for batch in batches:\n        text, label = zip(*batch) #Unzip the labels and text\n        model.update(text, label, sgd = optimize, losses = losses) #Update the model with the new data\n    \n    return losses #Return the losses","execution_count":351,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I had initially been trying to count sentiments like Extremely Negative and Negative separately, but that gave a loss of 32 with batches of 10. It also took over an hour. To compare, this took a few minutes to finish with a loss of about 1 at batches of 30. I guess it is hard to quantify \"Extremely\".\n\nAlso, I initially trained the model here and then predicted later, but I decided to have all the heavy lifting in one place."},{"metadata":{},"cell_type":"markdown","source":"---"},{"metadata":{},"cell_type":"markdown","source":"# Prediction on Test set"},{"metadata":{"trusted":true},"cell_type":"code","source":"#PredictTexts: predicts the sentiment of the tweet, from negative to positive\n#Input: the model and the tweets\n#Output: predictions\ndef predictTexts(model, texts):\n    predicText = [model.tokenizer(text) for text in texts] #Tokenizes the test tweets\n    model.get_pipe(\"textcat\") #Gets the trained textcat pipe\n    scores,_ = textcat.predict(predicText) #Gets the scores from the predictions, ignoring other outputs\n    classes = scores.argmax(axis = 1) #Get the highest ranked prediction score for each tweet\n    return classes #Returns the predictions","execution_count":352,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#CheckAccuracy: checks the accuracy compared to the predictions.\n#Input: the NLP model, the tweets to predict, their pre-determined labels\n#Output: the accuracy of the predictions\ndef checkAccuracy(model, texts, labels):\n    predicted = predictTexts(model, texts) #Creates predictions on the tweets\n    trueVal = [2*int(label[\"cats\"][\"Positive\"]) + int(label[\"cats\"][\"Neutral\"]) for label in labels] #Gets the actual value of the tweets provided\n    correct = 0 #A holder variable for how many predictions are correct\n    total = len(predicted) #The total number of analyzed tweets\n    \n    #For loop, comparing predictions to their values\n    for i in range(0,total):\n        if trueVal[i] == predicted[i]: #If the prediction is correct\n            correct+=1  #Add a point to the correct pile\n    \n    accuracy = correct/total #Get the accuracy of the number correct over the number total\n    return accuracy #Returns the accuracy of the model","execution_count":353,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---"},{"metadata":{},"cell_type":"markdown","source":"# Adding labels for the categories"},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = [] #Labels for the cleaned training tweet\nlabelsT = [] #The labels for the cleaned test tweet\n\n#For loop to add true and false to classifications for the train set\nfor i in range(0,len(train)): \n    label = train[\"Sentiment\"][i] #Get the sentiment\n    \n    #Categorize true false based on the labels\n    if label == \"Negative\":\n        cats = {\"Negative\" : True, \"Neutral\" : False, \"Positive\" : False}\n    elif label == \"Neutral\":\n        cats = {\"Negative\" : False, \"Neutral\" : True, \"Positive\" : False}\n    else:\n        cats = {\"Negative\" : False, \"Neutral\" : False, \"Positive\" : True}\n    labels.append({'cats' : cats})\n\n#For loop to add true and false to classifications for the test set\nfor i in range(0,len(test)):\n    label = test[\"Sentiment\"][i] #Get the sentiment\n    \n    #Categorize true false based on the labels\n    if label == \"Negative\":\n        cats = {\"Negative\" : True, \"Neutral\" : False, \"Positive\" : False}\n    elif label == \"Neutral\":\n        cats = {\"Negative\" : False, \"Neutral\" : True, \"Positive\" : False}\n    else:\n        cats = {\"Negative\" : False, \"Neutral\" : False, \"Positive\" : True}\n    labelsT.append({'cats' : cats})\n","execution_count":354,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---"},{"metadata":{},"cell_type":"markdown","source":"# Run the training and prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"texts = train[\"CleanTweet\"].copy() #Get the clean tweets\ntokenTexts = [nlp.tokenizer(tweet) for tweet in texts] #Tokenize the training tweets\noptimize = nlp.begin_training() #The optimizer, using spacy\ndata = list(zip(tokenTexts, labels)) #Zipping the labels and texts together\n\nlosses = trainData(nlp, data, optimize) #Train the model\naccuracy = checkAccuracy(nlp, test[\"CleanTweet\"].copy(), labelsT) #Gets the accuracy of predictions for the trained model\nprint(\"Losses: \", losses[\"textcat\"], \"Accuracy: \", accuracy) #Prints the loss when training and the accuracy","execution_count":355,"outputs":[{"output_type":"stream","text":"Losses:  17.024992450140417 Accuracy:  0.7623814541622761\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"The initial accuracy was 19%, however, it was when I was giving labels before I deleted the blank tweets. Just a note about the process."},{"metadata":{},"cell_type":"markdown","source":"---"},{"metadata":{},"cell_type":"markdown","source":"# Conclusion"},{"metadata":{},"cell_type":"markdown","source":"The highest accuracy I achieved was 76.2% with a loss of 17.025, that being with a batch size of 10. This is honestly a little lower than I was hoping. I used Spacy for this first NLP project in order following the Kaggle course, but I believe it was a limiting factor in this case. When trying to look up methods and other items, I would notice NLTK and Keras pop up way more commonly even with \"Spacy\" in the search term. This makes me think these are more common and possibly more powerful, but I think I will do a little bit more research before trying another project with one of those. Overall, however, I do think it was a good learning experience."}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}