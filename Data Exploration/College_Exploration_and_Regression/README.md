# College_Exploration_and_Regression--Kaggle

![Accept](https://github.com/Luna-McBride/Kaggle_Personal_Projects/blob/master/Data%20Exploration/College_Exploration_and_Regression/AcceptRate.png)

The Dataset: https://www.kaggle.com/yashgpt/us-college-data

The Notebook in Kaggle: https://www.kaggle.com/lunamcbride24/college-exploration-and-regression

My Kaggle: https://www.kaggle.com/lunamcbride24

This project utilizes a dataset of colleges that shows the amount of students enrolled, whether it is a private or public school, and other various factors. I did do a regression in this case, but I feel the exploration was more important in this case, hence why this is in the Data Exploration folder. This set is very strange, in that it has a strange collection of colleges and an interesting collection of columns used. This means that things like book cost, percent of students from a top 10% high school, and percentage of alumni who donate are natively in the dataset, while I had calculate acceptance rate separately. The acceptance rate is also the only graph I would like to emphasize here (above), given it does not need to be scaled like other attributes to give information and having to calculate it myself means it does not have the oddities that graduation rate has (ranges for each one shown below, but I emphasize this one specifically now because of the single college that has a graduation rate over 100%). 

![Range](https://github.com/Luna-McBride/Kaggle_Personal_Projects/blob/master/Data%20Exploration/College_Exploration_and_Regression/CollegeRanges.png)

There is a large amount of variance between the colleges here. I will go through these variables in a bit more depth: 

* The number of applicants, acceptances, and enrollments have a wide range from double digits to tens of thousands, which reveals the scope of the colleges chosen. I want to emphasize that schools like Harvard are not in the dataset, which skews the data in some areas, including here.
* The number of students from the top n% is honestly a bit strange here. Of course the biggest names are not in the dataset, so that is likely why these numbers are low. 
* The full and part time student numbers can get above enrollment rates, which is due to these variables being of their overall student bodies. I just wanted to point that out to prevent confusion. 
* The cost columns here do cover a wide variety of important aspects to costs. I find it odd that in state tuition is not here so the overall cost variable that I made (further down) is under the presumption of out of state tuition. It is also unclear if this is by semester or by year, which would really change the scale when it comes to the cost of these colleges, especially given their ranges.
* Teachers with PhD, Teachers with Terminal Degrees, and Expenditure per Student are also strange here. I think these act more as a "look at how prestious and high quality these schools are" without including a direct teacher count/other school expenses report to gage where the money is going or how many teachers proportionally have higher degrees. It seems a bit disingenuous.
* Student Faculty Ratios and Percentage of Alumni who donate is actually very interesting here. They show how personalized the education experience is as well as the amount of alumni who put support their school to the point to giving them money. Of course this data is better for looking on a case by case basis rather than by aggregate, but it would be very interesting to see on a more singular or small group level if this had location data as well. The ranges between small and big ratios and high vs low alumni donation percentages could really show interestng things if presented by location.
* I already made note of the college with a graduation rate above 100%, which soured my perception of this column. This one could very well have over-reporting issues, since there are also a lot of them with 100% graduation rates. This could be flubbed numbers or colleges meant to push everyone through, but it told me I could not trust this one enough to use it further for regressions like I had initially planned.
* The Overall Cost and Acceptance Rate columns are ones I built myself using related columns in the dataset. The overall cost still has the issue of semester versus by year charge that I mentioned before, but I am impressed how low some of these are even despite this issue. Acceptance rate, on the other hand, was the one I decided to do a regression for specifically due to its range. It goes from 0.15 to 1.0. 0.15 is still higher than places like Stanford and 1.0 comes from entries that accept all students (which is only 7 of them). This ended up being more complex than I thought, but more on that below.

![Regression](https://github.com/Luna-McBride/Kaggle_Personal_Projects/blob/master/Data%20Exploration/College_Exploration_and_Regression/ForestExample.png)

Above is an outcome from when I attepted to use a random forest regression for the acceptance rate data. The accuracies would be all over the place, but would always have a low root mean square error. This tells me that the predictions the forest made were always close, but would just have problems with being exact. It could get the gist of how many people it could accept, but was only right on the dot sometimes (hence the wide ranges of accuracies). This example is the best of a list of five, which I pulled to show the important characteristics it decided on. It always tended to strongly take into account the top n% students, number of applicants, and cost. This tells me that the schools that could draw in more and better students would typically accept less, likely due to competition. They could then charge higher prices for the honor of going there, which in itself becomes an indecator. These aspects could change places by run of course, but the ones in this example tended to be the most common between runs. This one just provided the best example, since it had a higher accuracy and included those factors. 
